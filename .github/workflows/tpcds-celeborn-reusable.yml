name: TPC-DS-Celeborn-Reusable

on:
  workflow_call:
    inputs:
      celebornver:
        required: true
        type: string
      celebornurl:
        required: true
        type: string

jobs:
  test-spark-35-celeborn:
    name: Test spark-3.5 celeborn-${{ inputs.celebornver }}
    uses: ./.github/workflows/tpcds-reusable.yml
    with:
      sparkver: spark-3.5
      sparkurl: https://archive.apache.org/dist/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz
      extrablazebuildopt: -Pceleborn-${{ inputs.celebornver }} -DcelebornScope=compile
      extrablazeidentifier: celeborn-${{ inputs.celebornver }}
      extracmds: |
        wget -c ${{ inputs.celebornurl }} && \
        mkdir -p celeborn-bin-${{ inputs.celebornver }} && \
        cd celeborn-bin-${{ inputs.celebornver }} && tar -xf ../apache-celeborn-*.tgz --strip-component=1 && \
        mv ./conf/celeborn-env.sh.template ./conf/celeborn-env.sh && \
        bash -c "echo -e 'CELEBORN_MASTER_MEMORY=4g\nCELEBORN_WORKER_MEMORY=4g\nCELEBORN_WORKER_OFFHEAP_MEMORY=8g' > ./conf/celeborn-env.sh" && \
        bash -c "echo -e 'celeborn.worker.commitFiles.threads 128\nceleborn.worker.sortPartition.threads 64' > ./conf/celeborn-defaults.conf" && \
        bash ./sbin/start-master.sh && \
        bash ./sbin/start-worker.sh
      extrasparkconf: >-
        --conf spark.shuffle.manager=org.apache.spark.sql.execution.blaze.shuffle.celeborn.BlazeCelebornShuffleManager
        --conf spark.serializer=org.apache.spark.serializer.KryoSerializer
        --conf spark.celeborn.master.endpoints=localhost:9097
        --conf spark.celeborn.client.spark.shuffle.writer=hash
        --conf spark.celeborn.client.push.replicate.enabled=false
